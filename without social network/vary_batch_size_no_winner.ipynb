{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file runs study 1, no winner case, without spillover effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.core.fromnumeric import repeat\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_coverage(data,n_trials,n_resamples,true_val):\n",
    "    xb = np.random.choice(data, (n_resamples, n_trials), replace=True)\n",
    "    low,high=st.t.interval(0.95, len(xb)-1, loc=np.mean(xb), scale=st.sem(xb))\n",
    "    return np.sum(np.logical_and(true_val >= low, true_val <= high))/n_trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAB:\n",
    "    def __init__(self, probs, karms, nfirst, nEpisodes):\n",
    "        '''\n",
    "        meanings for the parameters:\n",
    "        probs: True success rate for each arm k in {1, ..., K} \n",
    "        kArms: Number of arms to choose among\n",
    "        nsamples: Number of subjects to test at each time step\n",
    "\n",
    "        '''\n",
    "        self.n_obs = 4000\n",
    "        self.probs = probs\n",
    "        self.K = karms\n",
    "        self.n = int((self.n_obs-nfirst)/(nEpisodes-1)) if nEpisodes > 1 else 0\n",
    "        self.T = nEpisodes\n",
    "        self.first = nfirst\n",
    "        self.true_win_arm = np.argmax(np.asarray(probs))\n",
    "\n",
    "    def best_arm(self, s:np.ndarray, asgn):\n",
    "        draws = 10000\n",
    "        # + 1 for a Beta(1, 1) prior\n",
    "        new_alpha = s+1\n",
    "        new_beta = asgn-s+1\n",
    "        selection_table = []\n",
    "        for i in range(self.K):\n",
    "            theta = np.random.beta(new_alpha[i], new_beta[i], draws)\n",
    "            selection_table.append(theta)\n",
    "\n",
    "        winning_arms = np.argmax(selection_table, axis = 0)\n",
    "        winning_prob = []\n",
    "        \n",
    "#         for i in range(self.K):\n",
    "#             winning_prob.append(winning_arms.count(i)/draws)\n",
    "        c = Counter(winning_arms)\n",
    "        winning_prob = np.zeros(self.K)\n",
    "        for i in range(self.K):\n",
    "            winning_prob[i] = c[i]/draws\n",
    "\n",
    "        return winning_prob\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        # initialization\n",
    "        success = np.zeros((self.T, self.K))   # record the success cases of each arm at each time step\n",
    "        assigned = np.zeros((self.T, self.K)) # record the assigned cases of each arm at each time step\n",
    "        posterior_probs = 0 # estimated success rate\n",
    "        winning_probs = np.zeros((self.T, self.K)) # probability to be the true best arm\n",
    "        # rewards = np.zeros(self.T) # record the average rewards per period\n",
    "        # regrets = np.zeros(self.T) # record the regrets per period\n",
    "        return (success, assigned, posterior_probs, winning_probs)\n",
    "\n",
    "\n",
    "    def do_experiment(self, assignments):\n",
    "        c = Counter(assignments)\n",
    "        assigned = [c[i] for i in range(self.K)]\n",
    "        success = [np.random.binomial(assigned[i], self.probs[i]) for i in range(self.K)]\n",
    "        return assigned, success\n",
    "\n",
    "\n",
    "    def Thompson_sampling(self):\n",
    "        # initialization\n",
    "        (success, assigned, posterior_probs, winning_probs) = self.reset()\n",
    "\n",
    "        # for round 1, samples are randomly assigned\n",
    "        new_assign = np.random.choice(range(self.K), size=self.first)\n",
    "        assigned[0], success[0]  = self.do_experiment(new_assign)\n",
    "        posterior_probs = success[0,0]/ assigned[0,0]\n",
    "        winning_probs[0] = self.best_arm(success[0], assigned[0])\n",
    "        adj_probs = success[0][0]*self.K/self.first\n",
    "        # print(adj_probs)\n",
    "        if self.T > 1:\n",
    "            count0 = 0\n",
    "            for i in range(1, self.T):              \n",
    "                new_assign = np.random.choice(range(self.K), size=self.n, p=list(winning_probs[i-1])) # adaptive design\n",
    "                new_assigned, new_success = self.do_experiment(new_assign)\n",
    "                assigned[i] = assigned[i-1]+ new_assigned\n",
    "                success[i] = success[i-1]+ new_success\n",
    "                winning_probs[i] = self.best_arm(success[i], assigned[i])\n",
    "                if winning_probs[i-1,0] == 0:\n",
    "                    count0 += 1\n",
    "                else:\n",
    "                    adj_probs += new_success[0]/winning_probs[i-1,0]/self.n\n",
    "            posterior_probs = adj_probs / (self.T-count0)\n",
    "        return (success, assigned, posterior_probs, winning_probs)\n",
    "    \n",
    "\n",
    "\n",
    "    def static(self):\n",
    "        # initialization\n",
    "        (success, assigned, posterior_probs, winning_probs) = self.reset()\n",
    "\n",
    "        # for round 1, samples are randomly assigned\n",
    "        new_assign = np.random.choice(range(self.K), size=self.first).tolist()\n",
    "        assigned[0], success[0]  = self.do_experiment(new_assign)\n",
    "        posterior_probs = success[0,0]/ assigned[0,0]\n",
    "        winning_probs[0] = self.best_arm(success[0], assigned[0])\n",
    "        adj_probs = success[0][0]*self.K/self.first\n",
    "        for i in range(1, self.T):\n",
    "            new_assign = np.random.choice(range(self.K), size=self.n).tolist() # static design\n",
    "            new_assigned, new_success = self.do_experiment(new_assign)\n",
    "            assigned[i] = assigned[i-1]+ new_assigned\n",
    "            success[i] = success[i-1]+ new_success\n",
    "            winning_probs[i] = self.best_arm(success[i], assigned[i])\n",
    "            adj_probs += new_success[0]*self.K/self.n\n",
    "        posterior_probs = adj_probs / self.T\n",
    "\n",
    "\n",
    "        return (success, assigned, posterior_probs, winning_probs)\n",
    "        \n",
    "    def do_replication(self, times, method):\n",
    "        '''\n",
    "        parameters:\n",
    "        final_regrets -- to record the final regret of each replication, in order to compare efficiency\n",
    "        final_win_arm -- to record the final win arm selected by two methods, in order to compare the accurarcy\n",
    "        final_win_probs -- to record the final probability of each arm being the best arm, in order to compare the accurarcy\n",
    "        final_assignment -- to record the final number of assigned subjects to the true best arm, comparing the exploitition\n",
    "        cum_rewards -- to record the total rewards of every replication\n",
    "        '''\n",
    "        # records of the replication\n",
    "        final_win_arm = np.zeros(times)\n",
    "        final_win_probs = np.zeros(shape = (times, self.K))\n",
    "        final_assignment = np.zeros(times) # only record the true best arm\n",
    "        estimation = np.zeros(times)\n",
    "        \n",
    "        if method == 'TS':\n",
    "            for i in range(times):\n",
    "                (success, assigned, posterior_probs, winning_probs) = self.Thompson_sampling()\n",
    "                final_win_arm[i] = np.argmax(winning_probs[-1])\n",
    "                final_win_probs[i] = winning_probs[-1]\n",
    "                final_assignment[i] = assigned[-1][self.true_win_arm]\n",
    "                estimation[i] = posterior_probs\n",
    "        else:\n",
    "            for i in range(times):\n",
    "                (success, assigned, posterior_probs, winning_probs) = self.static()\n",
    "                final_win_arm[i] = np.argmax(winning_probs[-1])\n",
    "                final_win_probs[i] = winning_probs[-1]\n",
    "                final_assignment[i] = assigned[-1][self.true_win_arm]\n",
    "                estimation[i] = posterior_probs\n",
    "\n",
    "        ate = np.mean(estimation)\n",
    "        mse = np.mean(np.square(np.subtract(estimation,self.probs[0])))\n",
    "        rmse = np.sqrt(mse)\n",
    "        # rmse = np.std(estimation,0)\n",
    "        low,high=st.t.interval(0.95, len(estimation)-1, loc=np.mean(estimation), scale=st.sem(estimation))\n",
    "        win_counts = Counter(final_win_arm)\n",
    "        estimate = {\"best_selected\":win_counts[0]/times,\"ATE\":ate, \"RMSE\":rmse, \"Coverage\":(low,high)}\n",
    "        print(estimate)\n",
    "        return (final_win_arm, final_win_probs, final_assignment, estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1\n",
    "k = 9 # number of treatments\n",
    "probs = [0.11] + [0.1]*8 # true value\n",
    "np.random.seed(99332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_selected': 0.2704, 'ATE': 0.10997202856810157, 'RMSE': 0.014742604526863233, 'Coverage': (0.10956325282106438, 0.11038080431513875)}\n",
      "{'best_selected': 0.27, 'ATE': 0.1099242, 'RMSE': 0.015774115664594322, 'Coverage': (0.10948682727789383, 0.11036157272210617)}\n"
     ]
    }
   ],
   "source": [
    "# exp 1\n",
    "first = 4000\n",
    "periods = 1\n",
    "sim1 = MAB(probs,k,first, periods)\n",
    "(s1_ts_final_win_arm, s1_ts_final_win_probs, s1_ts_final_assignment, s1_ts_estimation) = sim1.do_replication(5000, \"TS\")\n",
    "(s1_st_final_win_arm, s1_st_final_win_probs, s1_st_final_assignment, s1_st_estimation) = sim1.do_replication(5000, \"static\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_selected': 0.2648, 'ATE': 0.10999909014049747, 'RMSE': 0.034576895042637536, 'Coverage': (0.10904035713568867, 0.11095782314530626)}\n"
     ]
    }
   ],
   "source": [
    "# experiment 3\n",
    "first = 2000\n",
    "periods = 2\n",
    "sim3 = MAB(probs,k,first, periods)\n",
    "(s3_ts_final_win_arm, s3_ts_final_win_probs, s3_ts_final_assignment, s3_ts_estimation) = sim3.do_replication(5000, \"TS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_selected': 0.2902, 'ATE': 0.11012512594601272, 'RMSE': 0.03743011258541685, 'Coverage': (0.10908728597326409, 0.11116296591876135)}\n"
     ]
    }
   ],
   "source": [
    "# experiment 4\n",
    "first = 800\n",
    "periods = 5\n",
    "sim4 = MAB(probs,k,first, periods)\n",
    "(s4_ts_final_win_arm, s4_ts_final_win_probs, s4_ts_final_assignment, s4_ts_estimation) = sim4.do_replication(5000, \"TS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_selected': 0.2978, 'ATE': 0.11018075587874823, 'RMSE': 0.02721065694482421, 'Coverage': (0.10942628734489988, 0.11093522441259658)}\n"
     ]
    }
   ],
   "source": [
    "# experiment 5\n",
    "first = 400\n",
    "periods = 10\n",
    "sim5 = MAB(probs,k,first, periods)\n",
    "(s5_ts_final_win_arm, s5_ts_final_win_probs, s5_ts_final_assignment, s5_ts_estimation) = sim5.do_replication(5000, \"TS\")\n",
    "# (s5_st_final_win_arm, s5_st_final_win_probs, s5_st_final_assignment, s5_st_estimation) = sim5.do_replication(5000, \"static\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_selected': 0.2956, 'ATE': 0.10976784083486471, 'RMSE': 0.025671159268538923, 'Coverage': (0.10905607127990068, 0.11047961038982874)}\n"
     ]
    }
   ],
   "source": [
    "# experiment 2\n",
    "first = 200\n",
    "periods = 20\n",
    "sim2 = MAB(probs,k,first, periods)\n",
    "(s2_ts_final_win_arm, s2_ts_final_win_probs, s2_ts_final_assignment, s2_ts_estimation) = sim2.do_replication(5000, \"TS\")\n",
    "# (s2_st_final_win_arm, s2_st_final_win_probs, s2_st_final_assignment, s2_st_estimation) = sim2.do_replication(5000, \"static\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_selected': 0.3084, 'ATE': 0.10956065049564824, 'RMSE': 0.0236108572125012, 'Coverage': (0.10890609233727286, 0.11021520865402362)}\n"
     ]
    }
   ],
   "source": [
    "# experiment 7\n",
    "first = 80\n",
    "periods = 50\n",
    "sim7 = MAB(probs,k,first, periods)\n",
    "(s7_ts_final_win_arm, s7_ts_final_win_probs, s7_ts_final_assignment, s7_ts_estimation) = sim7.do_replication(5000, \"TS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-fad731c7549a>:66: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  posterior_probs = success[0,0]/ assigned[0,0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_selected': 0.309, 'ATE': 0.11012893049254999, 'RMSE': 0.023237392428755308, 'Coverage': (0.10948462416817575, 0.11077323681692422)}\n"
     ]
    }
   ],
   "source": [
    "# exp 6\n",
    "first = 40\n",
    "periods = 100\n",
    "sim6 = MAB(probs,k,first, periods)\n",
    "(s6_ts_final_win_arm, s6_ts_final_win_probs, s6_ts_final_assignment, s6_ts_estimation) = sim6.do_replication(5000, \"TS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
